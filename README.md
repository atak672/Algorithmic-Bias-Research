# Algorithmic Bias:<br>The Amplification of COVID-19 Bias Online

**⚠️ Trigger Warning (TW):** This project delves into harmful language and slurs encountered online.

## Overview  
This research explores how social media algorithms and user engagement may have exacerbated racism and xenophobia during the COVID-19 pandemic, focusing specifically on Asian communities in the U.S. The study investigates:
- How algorithms impact the visibility and spread of xenophobic and racist content.
- The role of user engagement in mitigating or amplifying such content.
- Mathematical models that could unintentionally foster discriminatory environments.
- Statistical correlations between the rise of hate speech and key events during the pandemic.

## Project Structure  
1. **`algorithmic_bias_covid_code.R`**:  
   - Contains all finalized code for data cleaning, analysis, and visualizations.  
   - Includes draft writing and references, but paths may need to be adjusted for local reproduction.

2. **`algorithmic_bias_covid_report.pdf`**:  
   - All finalized writing, including analysis, visualizations, and references, are compiled in this report.

3. **Data Folder**:  
   - Contains all raw data, primarily focused on tweet data and text analysis.  
   - Tweet IDs were sourced from **IEEEDataPort**, covering **March 2020 – March 2022**.  
   - All Tweet IDs were hydrated using **Hydrator Desktop**.
   - Contains foundation for certain visualizations as well (e.g. map overlays).